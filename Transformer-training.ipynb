{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOJT1GY/xueBeJskztJ0x8n"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["maxvit training"],"metadata":{"id":"yjtn1tYDm7wC"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"mT_7X4nKlibX"},"outputs":[],"source":["import os\n","import shutil\n","from tqdm import tqdm\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","import timm\n","from torch.utils.data import DataLoader\n","from sklearn.metrics import classification_report, confusion_matrix\n","import numpy as np\n","\n","class CFG:\n","    dataset_dir = \"/content/drive/rdd-2022/RDD_SPLIT\"\n","    work_dir = \"/content/drive/working/rdd2022-class\"\n","    img_size = 224\n","    batch_size = 32\n","    epochs = 50\n","    lr = 1e-4\n","    patience = 7\n","    num_workers = 2\n","    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","    class_map = {\n","        0: \"longitudinal_crack\",\n","        1: \"transverse_crack\",\n","        2: \"alligator_crack\",\n","        3: \"other_damage\",\n","        4: \"pothole\"\n","    }\n","\n","print(f\"Using device: {CFG.device}\")\n","\n","def create_classification_folders(root, split):\n","    img_dir = os.path.join(root, split, \"images\")\n","    lbl_dir = os.path.join(root, split, \"labels\")\n","    new_root = os.path.join(CFG.work_dir, split)\n","    os.makedirs(new_root, exist_ok=True)\n","    print(f\"Reorganizing {split} set...\")\n","    for img_name in tqdm(os.listdir(img_dir)):\n","        if not img_name.endswith((\".jpg\", \".png\", \".jpeg\")):\n","            continue\n","        img_path = os.path.join(img_dir, img_name)\n","        lbl_path = os.path.join(lbl_dir, os.path.splitext(img_name)[0] + \".txt\")\n","        if not os.path.exists(lbl_path):\n","            continue\n","        with open(lbl_path, \"r\") as f:\n","            lines = f.readlines()\n","            if not lines:\n","                continue\n","            cls_id = int(lines[0].split()[0])\n","        cls_name = CFG.class_map.get(cls_id, \"unknown\")\n","        cls_folder = os.path.join(new_root, cls_name)\n","        os.makedirs(cls_folder, exist_ok=True)\n","        shutil.copy(img_path, os.path.join(cls_folder, img_name))\n","    print(f\"{split} set ready at {new_root}\")\n","\n","create_classification_folders(CFG.dataset_dir, \"train\")\n","create_classification_folders(CFG.dataset_dir, \"val\")\n","\n","train_transforms = transforms.Compose([\n","    transforms.Resize((CFG.img_size, CFG.img_size)),\n","    transforms.RandomResizedCrop(CFG.img_size, scale=(0.8, 1.0)),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.RandomVerticalFlip(),\n","    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3),\n","    transforms.RandomRotation(10),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.485, 0.456, 0.406],\n","                         [0.229, 0.224, 0.225]),\n","])\n","\n","val_transforms = transforms.Compose([\n","    transforms.Resize((CFG.img_size, CFG.img_size)),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.485, 0.456, 0.406],\n","                         [0.229, 0.224, 0.225]),\n","])\n","\n","train_ds = datasets.ImageFolder(os.path.join(CFG.work_dir, \"train\"), transform=train_transforms)\n","val_ds = datasets.ImageFolder(os.path.join(CFG.work_dir, \"val\"), transform=val_transforms)\n","\n","train_loader = DataLoader(train_ds, batch_size=CFG.batch_size, shuffle=True, num_workers=CFG.num_workers, pin_memory=True)\n","val_loader = DataLoader(val_ds, batch_size=CFG.batch_size, shuffle=False, num_workers=CFG.num_workers, pin_memory=True)\n","\n","print(f\"Dataset Loaded | Classes: {train_ds.classes}\")\n","\n","model = timm.create_model(\"maxvit_tiny_tf_224.in1k\", pretrained=True, num_classes=len(train_ds.classes))\n","model = model.to(CFG.device)\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.AdamW(model.parameters(), lr=CFG.lr, weight_decay=1e-4)\n","scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=CFG.epochs)\n","scaler = torch.cuda.amp.GradScaler()\n","\n","def train_one_epoch():\n","    model.train()\n","    total_loss, correct, total = 0, 0, 0\n","    loop = tqdm(train_loader, desc=\"Train\", leave=False)\n","    for imgs, labels in loop:\n","        imgs, labels = imgs.to(CFG.device), labels.to(CFG.device)\n","        optimizer.zero_grad()\n","        with torch.cuda.amp.autocast():\n","            outputs = model(imgs)\n","            loss = criterion(outputs, labels)\n","        scaler.scale(loss).backward()\n","        scaler.step(optimizer)\n","        scaler.update()\n","        total_loss += loss.item() * imgs.size(0)\n","        _, preds = outputs.max(1)\n","        correct += preds.eq(labels).sum().item()\n","        total += labels.size(0)\n","    return total_loss / total, 100. * correct / total\n","\n","def validate():\n","    model.eval()\n","    total_loss, correct, total = 0, 0, 0\n","    preds_all, labels_all = [], []\n","    with torch.no_grad():\n","        for imgs, labels in tqdm(val_loader, desc=\"Valid\", leave=False):\n","            imgs, labels = imgs.to(CFG.device), labels.to(CFG.device)\n","            with torch.cuda.amp.autocast():\n","                outputs = model(imgs)\n","                loss = criterion(outputs, labels)\n","            total_loss += loss.item() * imgs.size(0)\n","            _, preds = outputs.max(1)\n","            correct += preds.eq(labels).sum().item()\n","            total += labels.size(0)\n","            preds_all.extend(preds.cpu().numpy())\n","            labels_all.extend(labels.cpu().numpy())\n","    acc = 100. * correct / total\n","    return total_loss / total, acc, preds_all, labels_all\n","\n","best_acc = 0\n","patience_counter = 0\n","\n","for epoch in range(CFG.epochs):\n","    train_loss, train_acc = train_one_epoch()\n","    val_loss, val_acc, preds, labels = validate()\n","    scheduler.step()\n","    print(f\"Epoch [{epoch+1}/{CFG.epochs}] Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}% | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%\")\n","    if val_acc > best_acc:\n","        best_acc = val_acc\n","        patience_counter = 0\n","        torch.save(model.state_dict(), \"best_maxvit_rdd2022.pth\")\n","        print(f\"New best model saved (Val Acc: {best_acc:.2f}%)\")\n","    else:\n","        patience_counter += 1\n","    if patience_counter >= CFG.patience:\n","        print(f\"Early stopping triggered at epoch {epoch+1}\")\n","        break\n","\n","print(\"Training Complete.\")\n","print(f\"Best Validation Accuracy: {best_acc:.2f}%\")\n","\n","model.load_state_dict(torch.load(\"best_maxvit_rdd2022.pth\"))\n","model.eval()\n","_, final_acc, preds, labels = validate()\n","print(f\"Final Validation Accuracy: {final_acc:.2f}%\")\n","print(\"Classification Report:\")\n","print(classification_report(labels, preds, target_names=train_ds.classes))\n","print(\"Confusion Matrix:\")\n","print(confusion_matrix(labels, preds))\n"]},{"cell_type":"markdown","source":["swin training"],"metadata":{"id":"NQKKHa4-nCXI"}},{"cell_type":"code","source":["import os, torch, timm\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, Dataset\n","from torchvision import transforms\n","from PIL import Image\n","from tqdm import tqdm\n","import pandas as pd\n","import numpy as np\n","\n","train_img_dir = \"/content/drive/rdd-2022/RDD_SPLIT/train/images\"\n","train_label_dir = \"/content/drive/rdd-2022/RDD_SPLIT/train/labels\"\n","val_img_dir = \"/content/drive/rdd-2022/RDD_SPLIT/val/images\"\n","val_label_dir = \"/content/drive/rdd-2022/RDD_SPLIT/val/labels\"\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","batch_size = 16\n","epochs = 50\n","lr = 1e-4\n","patience = 8\n","\n","def load_yolo_labels(img_dir, label_dir):\n","    paths, labels = [], []\n","    for img_file in os.listdir(img_dir):\n","        if img_file.endswith(\".jpg\"):\n","            paths.append(os.path.join(img_dir, img_file))\n","            lbl_file = os.path.join(label_dir, img_file.replace(\".jpg\", \".txt\"))\n","            if os.path.exists(lbl_file):\n","                with open(lbl_file, \"r\") as f:\n","                    lines = f.readlines()\n","                    labels.append(int(lines[0].split()[0]) if lines else 0)\n","            else:\n","                labels.append(0)\n","    return paths, labels\n","\n","train_paths, train_labels = load_yolo_labels(train_img_dir, train_label_dir)\n","val_paths, val_labels = load_yolo_labels(val_img_dir, val_label_dir)\n","num_classes = max(train_labels + val_labels) + 1\n","\n","print(f\"Dataset loaded {len(train_paths)} train, {len(val_paths)} val, {num_classes} classes\")\n","\n","transform_train = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.RandomVerticalFlip(),\n","    transforms.RandomRotation(20),\n","    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3),\n","    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n","])\n","\n","transform_val = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n","])\n","\n","class CustomDataset(Dataset):\n","    def __init__(self, paths, labels, transform):\n","        self.paths = paths\n","        self.labels = labels\n","        self.transform = transform\n","    def __len__(self):\n","        return len(self.paths)\n","    def __getitem__(self, idx):\n","        img = Image.open(self.paths[idx]).convert(\"RGB\")\n","        lbl = self.labels[idx]\n","        if self.transform:\n","            img = self.transform(img)\n","        return img, lbl\n","\n","train_loader = DataLoader(CustomDataset(train_paths, train_labels, transform_train),\n","                          batch_size=batch_size, shuffle=True, num_workers=2)\n","val_loader = DataLoader(CustomDataset(val_paths, val_labels, transform_val),\n","                        batch_size=batch_size, shuffle=False, num_workers=2)\n","\n","class SwinWithDropout(nn.Module):\n","    def __init__(self, num_classes):\n","        super().__init__()\n","        self.backbone = timm.create_model('swin_base_patch4_window7_224', pretrained=True, num_classes=0)\n","        self.dropout = nn.Dropout(0.5)\n","        self.fc = nn.Linear(self.backbone.num_features, num_classes)\n","    def forward(self, x):\n","        x = self.backbone(x)\n","        x = self.dropout(x)\n","        return self.fc(x)\n","\n","model = SwinWithDropout(num_classes).to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n","scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=3)\n","\n","best_acc = 0.0\n","wait = 0\n","train_acc_list, val_acc_list, train_loss_list, val_loss_list = [], [], [], []\n","\n","for epoch in range(epochs):\n","    model.train()\n","    train_loss, correct, total = 0, 0, 0\n","    for imgs, lbls in tqdm(train_loader, desc=f\"Epoch [{epoch+1}/{epochs}]\"):\n","        imgs, lbls = imgs.to(device), lbls.to(device)\n","        optimizer.zero_grad()\n","        out = model(imgs)\n","        loss = criterion(out, lbls)\n","        loss.backward()\n","        optimizer.step()\n","        train_loss += loss.item() * imgs.size(0)\n","        _, preds = out.max(1)\n","        correct += preds.eq(lbls).sum().item()\n","        total += lbls.size(0)\n","\n","    train_acc = 100 * correct / total\n","    train_loss /= total\n","\n","    model.eval()\n","    val_loss, val_correct, val_total = 0, 0, 0\n","    with torch.no_grad():\n","        for imgs, lbls in val_loader:\n","            imgs, lbls = imgs.to(device), lbls.to(device)\n","            out = model(imgs)\n","            loss = criterion(out, lbls)\n","            val_loss += loss.item() * imgs.size(0)\n","            _, preds = out.max(1)\n","            val_correct += preds.eq(lbls).sum().item()\n","            val_total += lbls.size(0)\n","\n","    val_acc = 100 * val_correct / val_total\n","    val_loss /= val_total\n","    scheduler.step(val_acc)\n","\n","    train_acc_list.append(train_acc)\n","    val_acc_list.append(val_acc)\n","    train_loss_list.append(train_loss)\n","    val_loss_list.append(val_loss)\n","\n","    print(f\"\\nEpoch {epoch+1}/{epochs}\")\n","    print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n","    print(f\"Val Loss:   {val_loss:.4f} | Val Acc:   {val_acc:.2f}%\")\n","\n","    if val_acc > best_acc:\n","        best_acc = val_acc\n","        torch.save(model.state_dict(), \"/content/drive/working/best_swin_transformer_full.pth\")\n","        print(\"Best model saved.\")\n","        wait = 0\n","    else:\n","        wait += 1\n","        print(f\"No improvement for {wait} epoch(s)\")\n","        if wait >= patience:\n","            print(\"Early stopping triggered.\")\n","            break\n","\n","print(f\"Training complete : Best Validation Accuracy: {best_acc:.2f}%\")\n","\n","history = pd.DataFrame({\n","    \"Epoch\": range(1, len(train_acc_list)+1),\n","    \"Train_Acc\": train_acc_list,\n","    \"Val_Acc\": val_acc_list,\n","    \"Train_Loss\": train_loss_list,\n","    \"Val_Loss\": val_loss_list\n","})\n"],"metadata":{"id":"0Eo5TPQkm658"},"execution_count":null,"outputs":[]}]}