{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oydKtV7I2vtR"
      },
      "outputs": [],
      "source": [
        "\n",
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRYMmtEX3Lji"
      },
      "source": [
        "Load yolo model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZpWVEtJV2yyU"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "yolo = YOLO(\"/content/drive/MyDrive/Colab Notebooks/MINIPROJECT/best.pt\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DafRdagb3X4o"
      },
      "source": [
        "Load swin Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yONZNrJE2zX0"
      },
      "outputs": [],
      "source": [
        "import timm\n",
        "import torch\n",
        "import re\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "ckpt = torch.load(\"/content/drive/MyDrive/Colab Notebooks/MINIPROJECT/best_fusionnet.pth\", map_location=\"cpu\")\n",
        "ckpt = {re.sub(r\"^swin\\.\", \"\", k): v for k, v in ckpt.items()}\n",
        "\n",
        "\n",
        "swin = timm.create_model(\"swin_base_patch4_window7_224\", pretrained=False, num_classes=0)\n",
        "swin.load_state_dict(ckpt, strict=False)\n",
        "swin = swin.to(device)\n",
        "swin.eval()\n",
        "\n",
        "swin_fc = nn.Linear(1024, NUM_CLASSES).to(device)\n",
        "\n",
        "def swin_forward(img):\n",
        "    with torch.no_grad():\n",
        "        feat = swin.forward_features(img)     # [1, 7, 7, 1024]\n",
        "        feat = feat.permute(0, 3, 1, 2)       # → [1, 1024, 7, 7]\n",
        "        feat = F.adaptive_avg_pool2d(feat, (1, 1))  # → [1,1024,1,1]\n",
        "        feat = feat.view(feat.size(0), -1)    # → [1,1024]\n",
        "        out = swin_fc(feat)                   # → [1,5]\n",
        "    return out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crlwZUCs3asq"
      },
      "source": [
        "Load Maxvit Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hlwyq9sx25SR"
      },
      "outputs": [],
      "source": [
        "import timm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import re\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "NUM_CLASSES = 5\n",
        "\n",
        "ckpt = torch.load(\"/content/drive/MyDrive/Colab Notebooks/MINIPROJECT/best_maxvit_rdd2022.pth\", map_location=\"cpu\")\n",
        "\n",
        "\n",
        "ckpt = {re.sub(r\"^maxvit\\.\", \"\", k): v for k, v in ckpt.items()}\n",
        "\n",
        "maxvit = timm.create_model(\"maxvit_tiny_tf_224.in1k\", pretrained=False, num_classes=1000)\n",
        "\n",
        "filtered_weights = {k: v for k, v in ckpt.items() if not k.startswith(\"head\")}\n",
        "missing, unexpected = maxvit.load_state_dict(filtered_weights, strict=False)\n",
        "\n",
        "in_features = maxvit.head.fc.in_features\n",
        "maxvit.head.fc = nn.Linear(in_features, NUM_CLASSES)\n",
        "\n",
        "maxvit = maxvit.to(device)\n",
        "maxvit.eval()\n",
        "\n",
        "print(\"MaxViT head adjusted to 5 output classes.\")\n",
        "print(\"MaxViT-Tiny restored successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YpBC_s6627QU"
      },
      "outputs": [],
      "source": [
        "CLASS_NAMES = [\n",
        "    'longitudinal crack',\n",
        "    'transverse crack',\n",
        "    'alligator crack',\n",
        "    'other corruption',\n",
        "    'Pothole'\n",
        "]\n",
        "\n",
        "from torchvision import transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JRb6x5cx2-aY"
      },
      "outputs": [],
      "source": [
        "def classify_ensemble(pil_crop, yolo_cls, yolo_conf):\n",
        "    import torchvision.transforms as T\n",
        "\n",
        "    transform = T.Compose([\n",
        "        T.Resize((224,224)),\n",
        "        T.ToTensor(),\n",
        "    ])\n",
        "    img_t = transform(pil_crop).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        p_swin = F.softmax(swin_forward(img_t), dim=1)\n",
        "        p_max  = F.softmax(maxvit(img_t), dim=1)\n",
        "\n",
        "        p_cls = (p_swin + p_max) / 2   # classifier average\n",
        "\n",
        "        yolo_vec = torch.zeros_like(p_cls)\n",
        "        yolo_vec[0, yolo_cls] = yolo_conf\n",
        "\n",
        "        # Weighted fusion (Classifier stronger!)\n",
        "        p = (p_cls * 0.7) + (yolo_vec * 0.3)\n",
        "\n",
        "        final_cls = torch.argmax(p, dim=1).item()\n",
        "        final_conf = p[0, final_cls].item()\n",
        "\n",
        "    return final_cls, final_conf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vlo8EQhO3AdV"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "from PIL import Image\n",
        "\n",
        "yolo = YOLO(\"/content/drive/MyDrive/Colab Notebooks/MINIPROJECT/best.pt\")\n",
        "\n",
        "def run_ensemble_on_image(img_path):\n",
        "    result = yolo(img_path, conf=0.15, iou=0.45)[0]\n",
        "    boxes = result.boxes\n",
        "\n",
        "    predictions = []\n",
        "\n",
        "    for box in boxes:\n",
        "        x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())\n",
        "        yolo_conf = float(box.conf.item())\n",
        "        yolo_cls = int(box.cls.item())\n",
        "\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        crop = img.crop((x1, y1, x2, y2))\n",
        "\n",
        "        cls, conf = classify_ensemble(crop, yolo_cls, yolo_conf)\n",
        "        predictions.append((CLASS_NAMES[cls], conf, (x1, y1, x2, y2)))\n",
        "\n",
        "    return predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ZrBmysO3CpP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix\n",
        "\n",
        "IOU_THRESHOLD = 0.4\n",
        "\n",
        "def compute_iou(box1, box2):\n",
        "    x1 = max(box1[0], box2[0])\n",
        "    y1 = max(box1[1], box2[1])\n",
        "    x2 = min(box1[2], box2[2])\n",
        "    y2 = min(box1[3], box2[3])\n",
        "\n",
        "    inter = max(0, x2 - x1) * max(0, y2 - y1)\n",
        "    area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
        "    area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
        "    union = area1 + area2 - inter\n",
        "    return inter / union if union > 0 else 0\n",
        "\n",
        "\n",
        "def evaluate_ensemble(test_images_dir, test_labels_dir):\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    total = 0\n",
        "    matched = 0\n",
        "\n",
        "    image_paths = sorted(glob.glob(test_images_dir + \"/*.jpg\"))\n",
        "\n",
        "    for img_path in image_paths:\n",
        "        label_path = os.path.join(test_labels_dir, os.path.basename(img_path).replace(\".jpg\", \".txt\"))\n",
        "        if not os.path.exists(label_path):\n",
        "            continue\n",
        "\n",
        "\n",
        "        result = yolo(img_path, conf=0.15, iou=0.45)[0]\n",
        "        boxes = result.boxes\n",
        "\n",
        "        # Load ground truth\n",
        "        gt_boxes = []\n",
        "        img = Image.open(img_path)\n",
        "        W, H = img.size\n",
        "\n",
        "        with open(label_path, \"r\") as f:\n",
        "            for line in f:\n",
        "                cls, xc, yc, w, h = map(float, line.split())\n",
        "                cls = int(cls)\n",
        "                x1 = (xc - w/2) * W\n",
        "                y1 = (yc - h/2) * H\n",
        "                x2 = (xc + w/2) * W\n",
        "                y2 = (yc + h/2) * H\n",
        "                gt_boxes.append((cls, (x1,y1,x2,y2)))\n",
        "\n",
        "        # Evaluate YOLO → Crop → Ensemble Classification\n",
        "        for box in boxes:\n",
        "            total += 1\n",
        "            x1,y1,x2,y2 = map(int, box.xyxy[0].tolist())\n",
        "            yolo_cls = int(box.cls.item())\n",
        "            yolo_conf = float(box.conf.item())\n",
        "\n",
        "            crop = img.crop((x1,y1,x2,y2))\n",
        "            pred_cls, pred_conf = classify_ensemble(crop, yolo_cls, yolo_conf)\n",
        "\n",
        "            # Store prediction for metrics\n",
        "            y_pred.append(pred_cls)\n",
        "\n",
        "            # Find best matching GT box\n",
        "            best_iou = 0\n",
        "            best_gt = None\n",
        "            for gt_cls, gt_box in gt_boxes:\n",
        "                iou = compute_iou((x1,y1,x2,y2), gt_box)\n",
        "                if iou > best_iou:\n",
        "                    best_iou = iou\n",
        "                    best_gt = gt_cls\n",
        "\n",
        "            if best_iou >= IOU_THRESHOLD:\n",
        "                y_true.append(best_gt)\n",
        "                if pred_cls == best_gt:\n",
        "                    matched += 1\n",
        "            else:\n",
        "                # no corresponding GT → false detection\n",
        "                y_true.append(-1)  # background/no match\n",
        "\n",
        "\n",
        "    y_true = np.array(y_true)\n",
        "    y_pred = np.array(y_pred)\n",
        "\n",
        "\n",
        "    mask = y_true != -1\n",
        "    y_true = y_true[mask]\n",
        "    y_pred = y_pred[mask]\n",
        "\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
        "    acc = np.mean(y_true == y_pred) * 100\n",
        "\n",
        "    print(f\"Ensemble Accuracy: {acc:.2f}%\")\n",
        "    print(f\"Precision: {precision:.3f}\")\n",
        "    print(f\"Recall: {recall:.3f}\")\n",
        "    print(f\"F1-Score: {f1:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ytbDZ-Z43Fqa"
      },
      "outputs": [],
      "source": [
        "evaluate_ensemble(\n",
        "    test_images_dir=\"/content/drive/MyDrive/Colab Notebooks/MINIPROJECT/RDD2022MAIN/RDD_SPLIT/test/images\",\n",
        "    test_labels_dir=\"/content/drive/MyDrive/Colab Notebooks/MINIPROJECT/RDD2022MAIN/RDD_SPLIT/test/labels\"\n",
        ")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
